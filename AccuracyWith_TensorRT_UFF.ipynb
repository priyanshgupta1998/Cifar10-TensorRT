{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AccuracyWith_TensorRT_UFF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lftHyTAGxy63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViFbD1atx1Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8b52e8c-0ca8-4350-e2fe-ca5801018e2f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6yAjSmh0TMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import time\n",
        "import os\n",
        "\n",
        "#using tensorflow keras as backend to build neural nets\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report   #confusion matrix to find the accuracy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler, CSVLogger\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PkjU2KQyHLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb4KcV-Uyj3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2f14d1ad-11e5-4deb-e151-942200c87c7b"
      },
      "source": [
        "!unzip '/content/gdrive/My Drive/Cifar10Assignment.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/Cifar10Assignment.zip\n",
            "  inflating: Cifar10TrainTensoflowModel.ipynb  \n",
            "  inflating: modelcheckpoint.hdf5    \n",
            "  inflating: saved_model.pb          \n",
            "  inflating: TensorFlow_with_GPU.ipynb  \n",
            "  inflating: variables.data-00000-of-00002  \n",
            "  inflating: variables.data-00001-of-00002  \n",
            "  inflating: variables.index         \n",
            "  inflating: cifar10_cnnWeightModel.h5  \n",
            "  inflating: cifar10_results.csv     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwGoDO5gKmO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "cfd2c69d-59b5-4ae6-9c8a-2d4fa4fd9938"
      },
      "source": [
        "\n",
        "model_load_tf = tf.keras.models.load_model('cifar10_cnnWeightModel.h5')\n",
        "model_load_tf.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,343,018\n",
            "Trainable params: 1,342,122\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSC0WKQaZHUI",
        "colab_type": "text"
      },
      "source": [
        "#Convert Keras model into TensorRT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9kfMJaG2sL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3d3d295c-6d2b-430c-bdeb-b5dc824a2ece"
      },
      "source": [
        "#insatall TensorRT 6.x\n",
        "!wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnvinfer6_6.0.1-1+cuda10.1_amd64.deb\n",
        "!dpkg -i libnvinfer6_6.0.1-1+cuda10.1_amd64.deb"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-01 13:46:28--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnvinfer6_6.0.1-1+cuda10.1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71245796 (68M) [application/x-deb]\n",
            "Saving to: ‘libnvinfer6_6.0.1-1+cuda10.1_amd64.deb’\n",
            "\n",
            "\r          libnvinfe   0%[                    ]       0  --.-KB/s               \r         libnvinfer  51%[=========>          ]  34.66M   173MB/s               \r        libnvinfer6  97%[==================> ]  66.29M   166MB/s               \rlibnvinfer6_6.0.1-1 100%[===================>]  67.94M   166MB/s    in 0.4s    \n",
            "\n",
            "2020-07-01 13:46:28 (166 MB/s) - ‘libnvinfer6_6.0.1-1+cuda10.1_amd64.deb’ saved [71245796/71245796]\n",
            "\n",
            "Selecting previously unselected package libnvinfer6.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack libnvinfer6_6.0.1-1+cuda10.1_amd64.deb ...\n",
            "Unpacking libnvinfer6 (6.0.1-1+cuda10.1) ...\n",
            "Setting up libnvinfer6 (6.0.1-1+cuda10.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrJ-osmfpHWq",
        "colab_type": "text"
      },
      "source": [
        "#link TensorRT with Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0mL8HCE2wJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3dcf175-73ed-4502-a0ce-c926247bf352"
      },
      "source": [
        "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
        "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_loaded_tensorrt_version\n",
        "print(f\"Linked TensorRT version {get_linked_tensorrt_version()}\")\n",
        "print(f\"Loaded TensorRT version {get_loaded_tensorrt_version()}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linked TensorRT version (6, 0, 1)\n",
            "Loaded TensorRT version (6, 0, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7UbtJKq3YIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dd05f7c-7065-4ec0-f6f4-b44942c5b557"
      },
      "source": [
        "# # force reset ipython namespaces\n",
        "# %reset -f\n",
        "#Convert .h5 model to .pb graph model\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# Clear any previous session.\n",
        "tf.keras.backend.clear_session()\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AInTCICw0sHl",
        "colab_type": "text"
      },
      "source": [
        "#Model conersion .h5 format to .pb graph format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P62i0AHZHDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dae3a22e-bb93-4f17-f142-70d627b5ef2e"
      },
      "source": [
        "save_pb_dir = ''\n",
        "model_fname = 'cifar10_cnnWeightModel.h5'\n",
        "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model.pb', save_pb_as_text=False):\n",
        "    with graph.as_default():\n",
        "        graphdef_inf = tf.compat.v1.graph_util.remove_training_nodes(graph.as_graph_def())\n",
        "        graphdef_frozen =  tf.compat.v1.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
        "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
        "        return graphdef_frozen\n",
        "\n",
        "# This line must be executed before loading Keras model.\n",
        "tf.keras.backend.set_learning_phase(0) \n",
        "\n",
        "model = tf.keras.models.load_model(model_fname)\n",
        "\n",
        "session = tf.compat.v1.keras.backend.get_session()\n",
        "\n",
        "input_names = [t.op.name for t in model.inputs]\n",
        "output_names = [t.op.name for t in model.outputs]\n",
        "\n",
        "# Prints input and output nodes names, take notes of them.\n",
        "print(input_names, output_names)\n",
        "\n",
        "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['conv2d_input_1'] ['dense_1_1/Softmax']\n",
            "INFO:tensorflow:Froze 40 variables.\n",
            "INFO:tensorflow:Converted 40 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCvNqaSoZG9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "59f452d8-09be-452f-f110-9baf0d8d29f5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul  1 10:01:47 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    57W / 149W |    296MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STGnG1KZZG5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "\n",
        "dpkg -i nvidia-machine-learning-repo-*.deb\n",
        "apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2T_bB29iWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Download TensorRT. 5.1.2.2\n",
        "# !apt-get install libnvinfer5\n",
        "# !wget -O nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb https://www.dropbox.com/s/45pz13r4e8ip4bl/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb?dl=0\n",
        "# !dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb\n",
        "# !apt-key add /var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227/7fa2af80.pub\n",
        "!apt-get update\n",
        "# !apt-get install -y --no-install-recommends libnvinfer5=5.1.2-1+cuda10.0\n",
        "# !apt-get install -y --no-install-recommends libnvinfer-dev=5.1.2-1+cuda10.0\n",
        "!apt-get install tensorrt\n",
        "!apt-get install python3-libnvinfer-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1W7UG-p5rwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49a5b832-3015-44f6-87af-5f60f77bfd34"
      },
      "source": [
        "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
        "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_loaded_tensorrt_version\n",
        "print(f\"Linked TensorRT version {get_linked_tensorrt_version()}\")\n",
        "print(f\"Loaded TensorRT version {get_loaded_tensorrt_version()}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linked TensorRT version (6, 0, 1)\n",
            "Loaded TensorRT version (6, 0, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMItrwlCBVsa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a021f404-ab7f-48ba-d3e5-a23ad835e806"
      },
      "source": [
        "!dpkg -l | grep TensorRT"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ii  libnvinfer-dev                          7.1.3-1+cuda11.0                                  amd64        TensorRT development libraries and headers\n",
            "ii  libnvinfer-plugin-dev                   7.1.3-1+cuda11.0                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer-plugin7                      7.1.3-1+cuda11.0                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer6                             6.0.1-1+cuda10.1                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvinfer7                             7.1.3-1+cuda11.0                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvonnxparsers-dev                    7.1.3-1+cuda11.0                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvonnxparsers7                       7.1.3-1+cuda11.0                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvparsers-dev                        7.1.3-1+cuda11.0                                  amd64        TensorRT parsers libraries\n",
            "ii  libnvparsers7                           7.1.3-1+cuda11.0                                  amd64        TensorRT parsers libraries\n",
            "ii  python3-libnvinfer                      7.1.3-1+cuda11.0                                  amd64        Python 3 bindings for TensorRT\n",
            "ii  python3-libnvinfer-dev                  7.1.3-1+cuda11.0                                  amd64        Python 3 development package for TensorRT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzdSEJVcZG0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8dc2d9f5-20d2-4d02-b909-08dc90c75a22"
      },
      "source": [
        "!dpkg -l | grep nvinfer"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ii  libnvinfer-dev                          7.1.3-1+cuda11.0                                  amd64        TensorRT development libraries and headers\n",
            "ii  libnvinfer-plugin-dev                   7.1.3-1+cuda11.0                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer-plugin7                      7.1.3-1+cuda11.0                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer6                             6.0.1-1+cuda10.1                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvinfer7                             7.1.3-1+cuda11.0                                  amd64        TensorRT runtime libraries\n",
            "ii  python3-libnvinfer                      7.1.3-1+cuda11.0                                  amd64        Python 3 bindings for TensorRT\n",
            "ii  python3-libnvinfer-dev                  7.1.3-1+cuda11.0                                  amd64        Python 3 development package for TensorRT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxFEIME4hOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dC4vcwP2jqX",
        "colab_type": "text"
      },
      "source": [
        "#Check if Tensor Core GPU is Present with compute_capability ==6.0 (TensorRT version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuyCPXofZGvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c057976e-8d56-4f6f-dcd4-0729799cda7e"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def check_tensor_core_gpu_present():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    for line in local_device_protos:\n",
        "        if \"compute capability\" in str(line):\n",
        "            compute_capability = float(line.physical_device_desc.split(\"compute capability: \")[-1])\n",
        "            if compute_capability>=6.0:\n",
        "                return True\n",
        "    \n",
        "print(\"Tensor Core GPU Present:\", check_tensor_core_gpu_present())\n",
        "tensor_core_gpu = check_tensor_core_gpu_present()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor Core GPU Present: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JduJjaW9Wx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62bf413d-cafb-4aac-95bd-60b3a44b9164"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWX1lXhrip1N",
        "colab_type": "text"
      },
      "source": [
        "### Inference with native TF2.0 saved model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJy3rd1peyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6ffefdc-9896-495b-eaf7-26b27327b670"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Gb8as-pnkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test.astype('float32')\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppEyvCFz7Ssp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20badbf5-8d1e-4d11-9594-82910c964b25"
      },
      "source": [
        "%%time\n",
        "model_fname = 'cifar10_cnnWeightModel.h5'\n",
        "LoadNaivemodel = tf.keras.models.load_model(model_fname)\n",
        "LoadNaivemodel.predict(X_test)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.63 s, sys: 951 ms, total: 5.58 s\n",
            "Wall time: 9.64 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkQziIOj3mJ_",
        "colab_type": "text"
      },
      "source": [
        "### TF-TRT FP32 model\n",
        "\n",
        "We first convert the TF native FP32 model to a TF-TRT FP32 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HR0rk7f3Wj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "104da5e5-14fd-4d0d-93c7-897524cd7ef5"
      },
      "source": [
        "\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "print('Converting to TF-TRT FP32...')\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,\n",
        "    outputs=output_names,\n",
        "    max_batch_size=1,\n",
        "    max_workspace_size_bytes=8000000000, #1 << 25,\n",
        "    precision_mode='FP32',\n",
        "    minimum_segment_size=50,\n",
        "    is_dynamic_op=True\n",
        ")\n",
        "graph_io.write_graph(trt_graph, \".\",\"cifar10NetFP32_trt_graph_saved_model.pb\", as_text=False)\n",
        "print('Done Converting to TF-TRT FP32')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to TF-TRT FP32...\n",
            "INFO:tensorflow:Linked TensorRT version: (6, 0, 1)\n",
            "INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\n",
            "Done Converting to TF-TRT FP32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL5ff0IfmWOY",
        "colab_type": "text"
      },
      "source": [
        "### TF-TRT FP16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Ve3QKImQZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef978f5e-5bbe-4c83-e585-e79162b26fa7"
      },
      "source": [
        "\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "print('Converting to TF-TRT FP16...')\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,\n",
        "    outputs=output_names,\n",
        "    max_batch_size=1,\n",
        "    max_workspace_size_bytes=8000000000, #1 << 25,\n",
        "    precision_mode='FP16',\n",
        "    minimum_segment_size=80,\n",
        "    is_dynamic_op=True\n",
        ")\n",
        "graph_io.write_graph(trt_graph, \".\",\"cifar10NetFP16_trt_graph_saved_model.pb\", as_text=False)\n",
        "print('Done Converting to TF-TRT FP16')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to TF-TRT FP16...\n",
            "INFO:tensorflow:Linked TensorRT version: (6, 0, 1)\n",
            "INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\n",
            "Done Converting to TF-TRT FP16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiVrHGDymYXE",
        "colab_type": "text"
      },
      "source": [
        "### TF-TRT INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCza0xiM8Oiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4c15943f-4ba3-47f3-fc5e-d9a7e6d8328b"
      },
      "source": [
        "\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "print('Converting to TF-TRT INT8...')\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,\n",
        "    outputs=output_names,\n",
        "    max_batch_size=1,\n",
        "    max_workspace_size_bytes=8000000000, #1 << 25,\n",
        "    precision_mode='INT8',\n",
        "    minimum_segment_size=50,\n",
        "    is_dynamic_op=True\n",
        ")\n",
        "graph_io.write_graph(trt_graph, \".\",\"cifar10NetINT8_trt_graph_saved_model.pb\", as_text=False)\n",
        "print('Done Converting to TF-TRT INT8')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to TF-TRT INT8...\n",
            "INFO:tensorflow:Linked TensorRT version: (6, 0, 1)\n",
            "INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\n",
            "Done Converting to TF-TRT INT8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hce4xgWxjEYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV-Z_qE6qU0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE_59FylqUwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joOCZw-cqUU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0pOXv1kqUPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlfZSotuqULH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXE_brRqUFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}